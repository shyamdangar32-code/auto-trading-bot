name: Multi-day Backtest

on:
  workflow_dispatch:
    inputs:
      start:
        description: "Start date (YYYY-MM-DD)"
        required: true
        default: "2025-09-08"
      end:
        description: "End date (YYYY-MM-DD) — exclusive (next day). Example: 2025-09-13"
        required: true
        default: "2025-09-13"
      underlying:
        description: "Symbol (NIFTY / BANKNIFTY)"
        required: true
        default: "NIFTY"
      interval:
        description: "Interval (e.g., 1m, 3m, 5m, 15m)"
        required: true
        default: "1m"
      capital_rs:
        description: "Capital (₹)"
        required: true
        default: "100000"
      order_qty:
        description: "Fallback order qty"
        required: true
        default: "1"

jobs:
  run-and-merge:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        profile: [loose, medium, strict]

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          python -m pip install pandas

      - name: Compute date list
        id: daterange
        shell: bash
        run: |
          python - <<'PY'
          import os, datetime as dt
          s = dt.date.fromisoformat(os.environ["INPUT_START"])
          e = dt.date.fromisoformat(os.environ["INPUT_END"])
          if not s < e:
            raise SystemExit("start must be < end")
          days = []
          d = s
          while d < e:
            # Mon=0 ... Sun=6 (skip Sat/Sun)
            if d.weekday() < 5:
              days.append(d.isoformat())
            d += dt.timedelta(days=1)
          out = ",".join(days)
          print("days=" + out)
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
            f.write("days=" + out + "\n")
          PY

      - name: Add repo to PYTHONPATH
        run: echo "PYTHONPATH=$PYTHONPATH:$(pwd)" >> $GITHUB_ENV

      - name: Run backtest for each day • ${{ matrix.profile }}
        env:
          ZERODHA_API_KEY: ${{ secrets.ZERODHA_API_KEY }}
          ZERODHA_ACCESS_TOKEN: ${{ secrets.ZERODHA_ACCESS_TOKEN }}
        shell: bash
        run: |
          IFS=',' read -ra DAYS <<< "${{ steps.daterange.outputs.days }}"
          for d in "${DAYS[@]}"; do
            nxt=$(python - <<PY
import datetime as dt, sys
d = dt.date.fromisoformat(sys.argv[1])
print((d + dt.timedelta(days=1)).isoformat())
PY
"$d")
            outdir="reports/${{ matrix.profile }}/$d"
            mkdir -p "$outdir"
            echo "▶ ${d} → ${nxt}  →  $outdir"
            python tools/run_backtest.py \
              --underlying "${{ inputs.underlying }}" \
              --start "$d" \
              --end "$nxt" \
              --interval "${{ inputs.interval }}" \
              --capital_rs "${{ inputs.capital_rs }}" \
              --order_qty "${{ inputs.order_qty }}" \
              --outdir "$outdir" \
              --use_block "backtest_${{ matrix.profile }}"
          done

      - name: Merge all days • ${{ matrix.profile }}
        env:
          PROFILE: ${{ matrix.profile }}
          RANGE_START: ${{ inputs.start }}
          RANGE_END: ${{ inputs.end }}
        shell: bash
        run: |
          python - <<'PY'
          import os, json, pandas as pd
          profile = os.environ["PROFILE"]
          base = f"reports/{profile}"
          days = sorted([d for d in os.listdir(base) if len(d) == 10 and d[4] == '-' and d[7] == '-'])
          merged_dir = f"reports/{profile}_merged"
          os.makedirs(merged_dir, exist_ok=True)

          rows, trades_all, equity_all = [], [], []

          for d in days:
            daydir = os.path.join(base, d)

            m = {}
            mpath = os.path.join(daydir, "metrics.json")
            if os.path.exists(mpath):
              try:
                with open(mpath) as fh:
                  m = json.load(fh)
              except Exception:
                m = {}
            rows.append({
              "date": d,
              "trades": m.get("trades"),
              "win_rate_%": m.get("win_rate"),
              "ROI_%": m.get("ROI"),
              "profit_factor": m.get("profit_factor"),
              "max_dd_%": m.get("max_dd_perc"),
              "sharpe": m.get("sharpe"),
            })

            tpath = os.path.join(daydir, "trades.csv")
            if os.path.exists(tpath):
              try:
                df = pd.read_csv(tpath)
                df["date"] = d
                trades_all.append(df)
              except Exception:
                pass

            epath = os.path.join(daydir, "equity.csv")
            if os.path.exists(epath):
              try:
                ef = pd.read_csv(epath)
                ef["date"] = d
                equity_all.append(ef)
              except Exception:
                pass

          table = pd.DataFrame(rows)
          table.to_csv(os.path.join(merged_dir, "per_day_metrics.csv"), index=False)

          if trades_all:
            pd.concat(trades_all, ignore_index=True).to_csv(
              os.path.join(merged_dir, "merged_trades.csv"), index=False
            )
          if equity_all:
            pd.concat(equity_all, ignore_index=True).to_csv(
              os.path.join(merged_dir, "merged_equity.csv"), index=False
            )

          summary = {}
          if not table.empty:
            summary["days"] = len(days)
            summary["trades"] = int(pd.to_numeric(table["trades"], errors="coerce").fillna(0).sum())
            summary["avg_win_rate_%"] = float(pd.to_numeric(table["win_rate_%"], errors="coerce").mean())
            summary["avg_profit_factor"] = float(pd.to_numeric(table["profit_factor"], errors="coerce").mean())
            summary["avg_ROI_%"] = float(pd.to_numeric(table["ROI_%"], errors="coerce").mean())
            summary["min_max_dd_%"] = float(pd.to_numeric(table["max_dd_%"], errors="coerce").min())
            summary["avg_sharpe"] = float(pd.to_numeric(table["sharpe"], errors="coerce").mean())

          with open(os.path.join(merged_dir, "summary.json"), "w") as f:
            json.dump(summary, f, indent=2)

          report_lines = [
            "# Multi-day Backtest (merged)",
            f"**Profile:** {profile}",
            f"**Range:** {os.environ['RANGE_START']} → {os.environ['RANGE_END']}",
            "",
            "## Summary",
            "```json",
            json.dumps(summary, indent=2),
            "```",
          ]
          # small preview table (up to 10 rows)
          try:
            report_lines += ["", "## Per-day metrics (preview)", table.head(10).to_markdown(index=False)]
          except Exception:
            pass

          with open(os.path.join(merged_dir, "REPORT.md"), "w") as f:
            f.write("\n".join(report_lines))
          PY

      - name: Upload merged artifact
        uses: actions/upload-artifact@v4
        with:
          name: multi-day-${{ matrix.profile }}-${{ inputs.start }}-to-${{ inputs.end }}
          path: |
            reports/${{ matrix.profile }}/*
            reports/${{ matrix.profile }}_merged/*
          if-no-files-found: error
