name: Multi-day Backtest

on:
  workflow_dispatch:
    inputs:
      start:
        description: "Start date (YYYY-MM-DD)"
        required: true
        default: "2025-09-08"
      end:
        description: "End date (YYYY-MM-DD) — exclusive (next day). Example: 2025-09-13"
        required: true
        default: "2025-09-13"
      underlying:
        description: "Symbol (NIFTY / BANKNIFTY)"
        required: true
        default: "NIFTY"
      interval:
        description: "Interval (e.g., 1m, 3m, 5m, 15m)"
        required: true
        default: "1m"
      capital_rs:
        description: "Capital (₹)"
        required: true
        default: "100000"
      order_qty:
        description: "Fallback order qty"
        required: true
        default: "1"

jobs:
  run-and-merge:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        profile: [loose, medium, strict]

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          python -m pip install pandas

      - name: Compute date list
        id: daterange
        shell: bash
        run: |
          python - <<'PY'
          import os, datetime as dt
          s = dt.date.fromisoformat(os.environ["INPUT_START"])
          e = dt.date.fromisoformat(os.environ["INPUT_END"])
          if not s < e:
            raise SystemExit("start must be < end")
          days = []
          d = s
          while d < e:
            # Skip Sat/Sun
            if d.weekday() < 5:
              days.append(d.isoformat())
            d += dt.timedelta(days=1)
          out = ",".join(days)
          print("days="+out)
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
            f.write("days="+out+"\n")
          PY

      - name: Add repo to PYTHONPATH
        run: echo "PYTHONPATH=$PYTHONPATH:$(pwd)" >> $GITHUB_ENV

      - name: Run backtest for each day • ${{ matrix.profile }}
        env:
          ZERODHA_API_KEY: ${{ secrets.ZERODHA_API_KEY }}
          ZERODHA_ACCESS_TOKEN: ${{ secrets.ZERODHA_ACCESS_TOKEN }}
        shell: bash
        run: |
          IFS=',' read -ra DAYS <<< "${{ steps.daterange.outputs.days }}"
          for d in "${DAYS[@]}"; do
            nxt=$(python - <<PY
import datetime as dt, sys
d = dt.date.fromisoformat(sys.argv[1])
print((d+dt.timedelta(days=1)).isoformat())
PY
"$d")
            outdir="reports/${{ matrix.profile }}/$d"
            mkdir -p "$outdir"
            echo "▶ ${d} → ${nxt}  →  $outdir"
            python tools/run_backtest.py \
              --underlying "${{ inputs.underlying }}" \
              --start "$d" \
              --end   "$nxt" \
              --interval "${{ inputs.interval }}" \
              --capital_rs "${{ inputs.capital_rs }}" \
              --order_qty "${{ inputs.order_qty }}" \
              --outdir "$outdir" \
              --use_block "backtest_${{ matrix.profile }}"
          done

      - name: Merge all days • ${{ matrix.profile }}
        shell: bash
        run: |
          python - <<'PY'
          import os, json, pandas as pd
          base = f"reports/${{ matrix.profile }}"
          days = sorted([d for d in os.listdir(base) if len(d)>=10 and d[:4].isdigit()])
          merged_dir = f"reports/${{ matrix.profile }}_merged"
          os.makedirs(merged_dir, exist_ok=True)

          rows, trades_all, equity_all = [], [], []

          for d in days:
            daydir = os.path.join(base, d)

            # metrics.json
            m = {}
            mp = os.path.join(daydir, "metrics.json")
            if os.path.exists(mp):
              try: m = json.load(open(mp))
              except Exception: m = {}
            rows.append({
              "date": d,
              "trades": m.get("trades"),
              "win_rate_%": m.get("win_rate"),
              "ROI_%": m.get("ROI"),
              "profit_factor": m.get("profit_factor"),
              "max_dd_%": m.get("max_dd_perc"),
              "sharpe": m.get("sharpe"),
            })

            # trades.csv
            tp = os.path.join(daydir, "trades.csv")
            if os.path.exists(tp):
              try:
                df = pd.read_csv(tp); df["date"] = d; trades_all.append(df)
              except Exception: pass

            # equity.csv
            ep = os.path.join(daydir, "equity.csv")
            if os.path.exists(ep):
              try:
                ef = pd.read_csv(ep); ef["date"] = d; equity_all.append(ef)
              except Exception: pass

          table = pd.DataFrame(rows)
          table.to_csv(os.path.join(merged_dir, "per_day_metrics.csv"), index=False)

          if trades_all:
            pd.concat(trades_all, ignore_index=True).to_csv(
              os.path.join(merged_dir, "merged_trades.csv"), index=False)
          if equity_all:
            pd.concat(equity_all, ignore_index=True).to_csv(
              os.path.join(merged_dir, "merged_equity.csv"), index=False)

          summary = {}
          if not table.empty:
            to_num = lambda s: pd.to_numeric(table[s], errors="coerce")
            summary = {
              "days": len(days),
              "trades": int(to_num("trades").fillna(0).sum()),
              "avg_win_rate_%": float(to_num("win_rate_%").mean()),
              "avg_profit_factor": float(to_num("profit_factor").mean()),
              "avg_ROI_%": float(to_num("ROI_%").mean()),
              "min_max_dd_%": float(to_num("max_dd_%").min()),
              "avg_sharpe": float(to_num("sharpe").mean()),
            }
          with open(os.path.join(merged_dir, "summary.json"), "w") as f:
            json.dump(summary, f, indent=2)

          lines = [
            "# Multi-day Backtest (merged)",
            f"**Profile:** ${{ matrix.profile }}",
            f"**Range:** ${{ inputs.start }} → ${{ inputs.end }}",
            "", "## Summary", "```json", json.dumps(summary, indent=2), "```",
            "", "## Per-day metrics (preview)",
            table.to_markdown(index=False) if not table.empty else "_no data_"
          ]
          open(os.path.join(merged_dir, "REPORT.md"), "w").write("\n".join(lines))
          PY

      - name: Upload merged artifact
        uses: actions/upload-artifact@v4
        with:
          name: multi-day-${{ matrix.profile }}-${{ inputs.start }}-to-${{ inputs.end }}
          path: |
            reports/${{ matrix.profile }}/*
            reports/${{ matrix.profile }}_merged/*
          if-no-files-found: error
